{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "x = open('text2.txt')\n",
    "h =[]\n",
    "for line in x:\n",
    "    line.rstrip()\n",
    "    y = re.findall('[0-9]+', line)\n",
    "    if len(y) < 1 :continue\n",
    "    for i in y:\n",
    "        h.append(int(i))\n",
    "m = sum(h)\n",
    "print(m)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "url = input('Enter - ') #https://py4e-data.dr-chuck.net/comments_42.html , https://py4e-data.dr-chuck.net/comments_1965933.html\n",
    "html = urlopen(url, context=ctx).read() # <class 'bytes'>\n",
    "#print('html: ', type(html))\n",
    "soup = BeautifulSoup(html, \"html.parser\") # <class 'bs4.BeautifulSoup'>\n",
    "#print('soup: ', type(soup)) # <class 'bs4.BeautifulSoup'>\n",
    "\n",
    "# Retrieve all of the anchor tags\n",
    "tags = soup('span') # <class 'bs4.element.ResultSet'>\n",
    "#print('tags: ', type(tags))\n",
    "suma = 0\n",
    "for tag in tags:\n",
    "    #print(type(tag))#<class 'bs4.element.Tag'>\n",
    "    #print(tag.contents) # <class 'list'>\n",
    "    suma += int(tag.contents[0])\n",
    "    print('Contents:', tag.contents[0])\n",
    "print(suma)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "url = input('Enter URL: ') # https://py4e-data.dr-chuck.net/known_by_Fikret.html , https://py4e-data.dr-chuck.net/known_by_J.html\n",
    "a = int(input('Enter count: '))\n",
    "Line = int(input('Enter position: '))\n",
    "\n",
    "print('retriving:', url)\n",
    "\n",
    "cn= 0\n",
    "while cn < a:\n",
    "    cn +=1\n",
    "    html = urlopen(url, context=ctx).read()\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    all_a_tags = soup.find_all('a')\n",
    "    third_a_tag = all_a_tags[Line - 1]\n",
    "    print('retriving:', str(third_a_tag.get('href', None)))\n",
    "    url = str(third_a_tag.get('href', None))\n",
    "\n",
    "# for i in range(0, a):\n",
    "#     html = urlopen(url, context=ctx).read()\n",
    "#     soup = BeautifulSoup(html, \"html.parser\")\n",
    "#     tags = soup('a')\n",
    "#     count = 0\n",
    "\n",
    "#     for tag in tags:\n",
    "#         count+=1\n",
    "#         if count == Line:\n",
    "#             print('retriving:', str(tag.get('href', None)))\n",
    "#             url = str(tag.get('href', None))\n",
    "#             count = 0\n",
    "#             break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import urllib.parse, urllib.error\n",
    "from urllib.request import urlopen\n",
    "\n",
    "url = 'https://py4e-data.dr-chuck.net/comments_42.xml'\n",
    "u = 'https://py4e-data.dr-chuck.net/comments_1965935.xml'\n",
    "response = urllib.request.urlopen(u) #type class http.client.HTTPResponse'>\n",
    "#print('response',type(response))\n",
    "xml_data = response.read() #type bytes\n",
    "#print('xml_data',type(xml_data))\n",
    "\n",
    "stuff = ET.fromstring(xml_data) # class 'xml.etree.ElementTree.Element\n",
    "#print('stuff',type(stuff))\n",
    "lst = stuff.findall('comments/comment') #list of bytes\n",
    "#print(lst)\n",
    "suma = 0\n",
    "lista =[]\n",
    "for i in lst:\n",
    "    a = i.find('count').text #this fount the tag count and convertit from bytes to strings\n",
    "    print(a)\n",
    "    lista.append(int(a))\n",
    "c = sum(lista)\n",
    "\n",
    "print(c)\n",
    "    \n",
    "# for item in lst:\n",
    "#      a = item.find('count').text\n",
    "#      b = int(a)\n",
    "#      suma += b\n",
    "# print(suma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib.parse, urllib.error\n",
    "from urllib.request import urlopen\n",
    "import ssl\n",
    "\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "data = input('enter:') # https://py4e-data.dr-chuck.net/comments_42.json ,  https://py4e-data.dr-chuck.net/comments_1965936.json\n",
    "\n",
    "uh = urllib.request.urlopen(data, context=ctx)\n",
    "#print('uh' , type(uh)) # <class 'http.client.HTTPResponse'>\n",
    "url = uh.read().decode()\n",
    "#print('url' , type(url)) # url <class 'str'>\n",
    "\n",
    "info = json.loads(url) #info <class 'dict'>\n",
    "#print('info', type(info)) # info <class 'dict'>\n",
    "\n",
    "c=0\n",
    "#print(\"info['comments']\" , type(info['comments'])) # info['comments'] <class 'list'>\n",
    "# for i in info['comments']:\n",
    "#     c += i['count']\n",
    "\n",
    "inf = info['comments'] #list of dictionaries\n",
    "print(inf)\n",
    "for i in inf:\n",
    "    c += i['count']\n",
    "\n",
    "print(c)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, urllib.parse\n",
    "import json, ssl\n",
    "\n",
    "# Heavily rate limited proxy of https://www.geoapify.com/ api\n",
    "serviceurl = 'https://py4e-data.dr-chuck.net/opengeo?'\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "while True:\n",
    "    address = input('Enter location: ')\n",
    "    if len(address) < 1: break\n",
    "\n",
    "    address = address.strip()\n",
    "    parms = dict()\n",
    "    parms['q'] = address\n",
    "\n",
    "    url = serviceurl + urllib.parse.urlencode(parms)\n",
    "\n",
    "    print('Retrieving', url)\n",
    "    uh = urllib.request.urlopen(url, context=ctx)\n",
    "    data = uh.read().decode()\n",
    "    print('Retrieved', len(data), 'characters', data[:20].replace('\\n', ' '))\n",
    "\n",
    "    try:\n",
    "        js = json.loads(data)\n",
    "    except:\n",
    "        js = None\n",
    "\n",
    "    if not js or 'features' not in js:\n",
    "        print('==== Download error ===')\n",
    "        print(data)\n",
    "        break\n",
    "\n",
    "    if len(js['features']) == 0:\n",
    "        print('==== Object not found ====')\n",
    "        print(data)\n",
    "        break\n",
    "\n",
    "    # print(json.dumps(js, indent=4))\n",
    "\n",
    "    plus_code = js['features'][0]['properties']['plus_code']\n",
    "    url = js['features'][0]['properties']['datasource']['url']\n",
    "    print('Retriving:', url)\n",
    "    print(len(js))\n",
    "    print('plus_code', plus_code, 'url', url)\n",
    "    location = js['features'][0]['properties']['formatted']\n",
    "    print(location)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
